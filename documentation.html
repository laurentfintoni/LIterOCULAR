<h1>Introduction</h1>

<p>
    This is the documentation for the digital magazine LiterOCULAR, made by Federico Cagnola and Laurent Fintoni for
    2021’s Information modelling and web technologies course in the DHDK Master’s programme, held by professor Fabio
    Vitali.
</p>
<p>
    Our work on this digital magazine was a great opportunity to experiment with different website layout and styles as
    well as to practice our markup and aesthetic skills.
</p>
<p>As instructed in the <a href="https://www.unibo.it/it/didattica/insegnamenti/insegnamento/2020/454464">project
        assignment</a> we started looking for a suitable subject for the two issues we were tasked to make: our shared
    passion for US hip-hop culture quickly led us to the character and cultural icon that was <b>MF DOOM</b>, and after
    some
    time we chose <b>Timnit Gebru</b>’s case as the second subject, given the its relevance in modern times and its
    importance
    to our field of study in general.
</p>
<hr>
<h1>Chapter I</h1>
<p>
    During the first phase of our research we dug into the web to search for meaningful pieces of text which could suit
    our
    project and the academic goal of building an enhanced reading experience. The complete list of sources and articles
    we
    gathered can be found in the “Disclaimer” section of our website.
</p>

<p>
    For the <b>first issue</b>, centered around the character of MF DOOM, we chose print-only magazines as sources:
    these
    articles
    spanned over seven years, from DOOM’s beginnings within the KMD group, to the loss of his brother, to his return as
    MF
    DOOM. In order to transform them into digitally encoded text, we used the pytesseract library in Python to extract
    all
    three articles, and captured embedded images with Adobe Photoshop.
</p>
<p>
    The process was very different for the <b>second issue</b>: the theme was Timnit Gebru’s incident at Google’s Ethics
    Division
    which ultimately caused her termination. Since the subject was close in time, all sources were already available in
    digital format: we retrieved the texts from online versions of The New York Times, MIT Tech Review and WAPO. These
    articles only span six months between each other, and detail the firing of Gebru as well as the larger theme of AI
    bias,
    which ultimately led to her dismissal.
</p>

<hr>
<h1>Chapter II</h1>
<p>
    After gathering the texts our markup work began, and in a couple of weeks all texts were marked up with a common
    strategy which would enable the implementation of the website’s functionality.
</p>
<p>
    We chose to give all texts a common
    layout, where headers would have a
    <code>h1</code> tag and most of the article would be in
    <code>p</code> tags. We added figures
    and
    <code>blockquotes</code> as necessary and then dove into the articles themselves, reflecting on the content and on
    what
    would be
    worthy of mention for our analysis.
</p>
<p>
    We started from the themes of our articles, music, racism,artificial intelligence
    <i>artificial intelligence</i>,identityreligionpeople
    placesto meventsconcepts such as <i>identity</i> and <i>religion</i>, and finally added useful tags to any
    <i>people</i>,
    <i>places</i> or <i>events</i> we found relevant. All important words or sentences were enclosed in a
    <code>span</code> tag with a
    class of
    <code>mention-*</code> where * would stand for the kind or class of mention and an additional attribute of
    <code>about=”*”</code>
    would clarify
    the specific entity mentioned. This double system, which was implemented partly by hand and partly through regular
    expressions
    matching, finally allowed us to have properly marked up text which in turn enabled the “intelligent” functionality
    of
    the website.
</p>

<h1>Chapter III</h1>